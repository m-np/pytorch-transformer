{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34fa65f5",
   "metadata": {
    "papermill": {
     "duration": 0.006628,
     "end_time": "2024-01-20T11:46:40.217229",
     "exception": false,
     "start_time": "2024-01-20T11:46:40.210601",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preparation for Machine Translation\n",
    "\n",
    "Library Imports for the jupyter notebook. We are refering to this [blog](https://medium.com/@hunter-j-phillips/putting-it-all-together-the-implemented-transformer-bfb11ac1ddfehttps://medium.com/@hunter-j-phillips/putting-it-all-together-the-implemented-transformer-bfb11ac1ddfe) to understand attention network in depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ab085ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:46:40.231993Z",
     "iopub.status.busy": "2024-01-20T11:46:40.231406Z",
     "iopub.status.idle": "2024-01-20T11:46:59.094472Z",
     "shell.execute_reply": "2024-01-20T11:46:59.093398Z"
    },
    "papermill": {
     "duration": 18.873248,
     "end_time": "2024-01-20T11:46:59.096812",
     "exception": false,
     "start_time": "2024-01-20T11:46:40.223564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q portalocker\n",
    "\n",
    "# importing required libraries\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "import spacy\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# torch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import torch.optim as optim\n",
    "\n",
    "# load and build datasets\n",
    "import torchtext\n",
    "from torchtext.data.functional import to_map_style_dataset\n",
    "from torch.nn.functional import pad\n",
    "from torch.utils.data import DataLoader\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torchtext.datasets as datasets\n",
    "import portalocker\n",
    "\n",
    "# visualization packages\n",
    "from mpl_toolkits import mplot3d\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeeeb3ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:46:59.111419Z",
     "iopub.status.busy": "2024-01-20T11:46:59.110453Z",
     "iopub.status.idle": "2024-01-20T11:46:59.120439Z",
     "shell.execute_reply": "2024-01-20T11:46:59.119144Z"
    },
    "papermill": {
     "duration": 0.019289,
     "end_time": "2024-01-20T11:46:59.122350",
     "exception": false,
     "start_time": "2024-01-20T11:46:59.103061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a2adc2",
   "metadata": {
    "papermill": {
     "duration": 0.005771,
     "end_time": "2024-01-20T11:46:59.134253",
     "exception": false,
     "start_time": "2024-01-20T11:46:59.128482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Reading the dataframe and converting it into iterable for consuming in pytorch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478a2af2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:46:59.147774Z",
     "iopub.status.busy": "2024-01-20T11:46:59.147426Z",
     "iopub.status.idle": "2024-01-20T11:46:59.152440Z",
     "shell.execute_reply": "2024-01-20T11:46:59.151242Z"
    },
    "papermill": {
     "duration": 0.014161,
     "end_time": "2024-01-20T11:46:59.154306",
     "exception": false,
     "start_time": "2024-01-20T11:46:59.140145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f498238f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:46:59.169032Z",
     "iopub.status.busy": "2024-01-20T11:46:59.168575Z",
     "iopub.status.idle": "2024-01-20T11:46:59.316348Z",
     "shell.execute_reply": "2024-01-20T11:46:59.314653Z"
    },
    "papermill": {
     "duration": 0.157704,
     "end_time": "2024-01-20T11:46:59.318586",
     "exception": false,
     "start_time": "2024-01-20T11:46:59.160882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>german</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two young, White males are outside near many b...</td>\n",
       "      <td>Zwei junge weiße Männer sind im Freien in der ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Several men in hard hats are operating a giant...</td>\n",
       "      <td>Mehrere Männer mit Schutzhelmen bedienen ein A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A little girl climbing into a wooden playhouse.</td>\n",
       "      <td>Ein kleines Mädchen klettert in ein Spielhaus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A man in a blue shirt is standing on a ladder ...</td>\n",
       "      <td>Ein Mann in einem blauen Hemd steht auf einer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Two men are at the stove preparing food.</td>\n",
       "      <td>Zwei Männer stehen am Herd und bereiten Essen zu.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0  Two young, White males are outside near many b...   \n",
       "1  Several men in hard hats are operating a giant...   \n",
       "2    A little girl climbing into a wooden playhouse.   \n",
       "3  A man in a blue shirt is standing on a ladder ...   \n",
       "4           Two men are at the stove preparing food.   \n",
       "\n",
       "                                              german  \n",
       "0  Zwei junge weiße Männer sind im Freien in der ...  \n",
       "1  Mehrere Männer mit Schutzhelmen bedienen ein A...  \n",
       "2  Ein kleines Mädchen klettert in ein Spielhaus ...  \n",
       "3  Ein Mann in einem blauen Hemd steht auf einer ...  \n",
       "4  Zwei Männer stehen am Herd und bereiten Essen zu.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/kaggle/input/machine-translation-dataset-de-en/translation_train.csv\"\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15ecb4a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:46:59.332846Z",
     "iopub.status.busy": "2024-01-20T11:46:59.332508Z",
     "iopub.status.idle": "2024-01-20T11:46:59.339271Z",
     "shell.execute_reply": "2024-01-20T11:46:59.338135Z"
    },
    "papermill": {
     "duration": 0.016203,
     "end_time": "2024-01-20T11:46:59.341199",
     "exception": false,
     "start_time": "2024-01-20T11:46:59.324996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29000, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17f71856",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:46:59.356424Z",
     "iopub.status.busy": "2024-01-20T11:46:59.356069Z",
     "iopub.status.idle": "2024-01-20T11:46:59.372986Z",
     "shell.execute_reply": "2024-01-20T11:46:59.371512Z"
    },
    "papermill": {
     "duration": 0.027599,
     "end_time": "2024-01-20T11:46:59.375577",
     "exception": false,
     "start_time": "2024-01-20T11:46:59.347978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform train - val split\n",
    "train_df = df.sample(frac=0.95, random_state=200)\n",
    "val_df = df.drop(train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a91bbc1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:46:59.390941Z",
     "iopub.status.busy": "2024-01-20T11:46:59.390557Z",
     "iopub.status.idle": "2024-01-20T11:46:59.396595Z",
     "shell.execute_reply": "2024-01-20T11:46:59.395525Z"
    },
    "papermill": {
     "duration": 0.016371,
     "end_time": "2024-01-20T11:46:59.398584",
     "exception": false,
     "start_time": "2024-01-20T11:46:59.382213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_iterable(sample_df):\n",
    "    \"\"\"\n",
    "    This converts pandas dataframe into list of tuples\n",
    "    consisting of (german sentences, english sentences).\n",
    "\n",
    "    This iterable in used in our data preparation\n",
    "    \"\"\"\n",
    "    sample_iter = sample_df.to_dict(orient=\"records\")\n",
    "    out_iter = [(dict1[\"german\"], dict1[\"english\"]) for dict1 in sample_iter]\n",
    "    print(f\"length of iterable: {len(out_iter)}\")\n",
    "    return out_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71d3a513",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:46:59.413576Z",
     "iopub.status.busy": "2024-01-20T11:46:59.413214Z",
     "iopub.status.idle": "2024-01-20T11:46:59.526352Z",
     "shell.execute_reply": "2024-01-20T11:46:59.525363Z"
    },
    "papermill": {
     "duration": 0.122861,
     "end_time": "2024-01-20T11:46:59.528289",
     "exception": false,
     "start_time": "2024-01-20T11:46:59.405428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of iterable: 27550\n",
      "length of iterable: 1450\n"
     ]
    }
   ],
   "source": [
    "train_iter = create_iterable(train_df)\n",
    "val_iter = create_iterable(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1388f7d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:46:59.542651Z",
     "iopub.status.busy": "2024-01-20T11:46:59.542291Z",
     "iopub.status.idle": "2024-01-20T11:46:59.560220Z",
     "shell.execute_reply": "2024-01-20T11:46:59.558949Z"
    },
    "papermill": {
     "duration": 0.028273,
     "end_time": "2024-01-20T11:46:59.563046",
     "exception": false,
     "start_time": "2024-01-20T11:46:59.534773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>german</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A man in an orange hat starring at something.</td>\n",
       "      <td>Ein Mann mit einem orangefarbenen Hut, der etw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Boston Terrier is running on lush green gras...</td>\n",
       "      <td>Ein Boston Terrier läuft über saftig-grünes Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A girl in karate uniform breaking a stick with...</td>\n",
       "      <td>Ein Mädchen in einem Karateanzug bricht einen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Five people wearing winter jackets and helmets...</td>\n",
       "      <td>Fünf Leute in Winterjacken und mit Helmen steh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>People are fixing the roof of a house.</td>\n",
       "      <td>Leute Reparieren das Dach eines Hauses.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             english  \\\n",
       "0      A man in an orange hat starring at something.   \n",
       "1  A Boston Terrier is running on lush green gras...   \n",
       "2  A girl in karate uniform breaking a stick with...   \n",
       "3  Five people wearing winter jackets and helmets...   \n",
       "4             People are fixing the roof of a house.   \n",
       "\n",
       "                                              german  \n",
       "0  Ein Mann mit einem orangefarbenen Hut, der etw...  \n",
       "1  Ein Boston Terrier läuft über saftig-grünes Gr...  \n",
       "2  Ein Mädchen in einem Karateanzug bricht einen ...  \n",
       "3  Fünf Leute in Winterjacken und mit Helmen steh...  \n",
       "4            Leute Reparieren das Dach eines Hauses.  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\n",
    "    \"/kaggle/input/machine-translation-dataset-de-en/translation_test.csv\"\n",
    ")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21597f9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:46:59.580461Z",
     "iopub.status.busy": "2024-01-20T11:46:59.580092Z",
     "iopub.status.idle": "2024-01-20T11:46:59.590891Z",
     "shell.execute_reply": "2024-01-20T11:46:59.589522Z"
    },
    "papermill": {
     "duration": 0.022199,
     "end_time": "2024-01-20T11:46:59.593452",
     "exception": false,
     "start_time": "2024-01-20T11:46:59.571253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of iterable: 1000\n"
     ]
    }
   ],
   "source": [
    "test_iter = create_iterable(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae389e1",
   "metadata": {
    "papermill": {
     "duration": 0.00699,
     "end_time": "2024-01-20T11:46:59.607502",
     "exception": false,
     "start_time": "2024-01-20T11:46:59.600512",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create Vocab from data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89ff0ee7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:46:59.623123Z",
     "iopub.status.busy": "2024-01-20T11:46:59.622697Z",
     "iopub.status.idle": "2024-01-20T11:46:59.629508Z",
     "shell.execute_reply": "2024-01-20T11:46:59.628215Z"
    },
    "papermill": {
     "duration": 0.017996,
     "end_time": "2024-01-20T11:46:59.632327",
     "exception": false,
     "start_time": "2024-01-20T11:46:59.614331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_tokenizers():\n",
    "    \"\"\"\n",
    "    Load the German and English tokenizers provided by spaCy.\n",
    "\n",
    "    Returns:\n",
    "        spacy_de:     German tokenizer\n",
    "        spacy_en:     English tokenizer\n",
    "    \"\"\"\n",
    "    try:\n",
    "        spacy_de = spacy.load(\"de_core_news_sm\")\n",
    "    except OSError:\n",
    "        os.system(\"python -m spacy download de_core_news_sm\")\n",
    "        spacy_de = spacy.load(\"de_core_news_sm\")\n",
    "\n",
    "    try:\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "    except OSError:\n",
    "        os.system(\"python -m spacy download en_core_web_sm\")\n",
    "        spacy_en = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "    print(\"Loaded English and German tokenizers.\")\n",
    "    return spacy_de, spacy_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58323bb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:46:59.649103Z",
     "iopub.status.busy": "2024-01-20T11:46:59.648551Z",
     "iopub.status.idle": "2024-01-20T11:46:59.653379Z",
     "shell.execute_reply": "2024-01-20T11:46:59.652574Z"
    },
    "papermill": {
     "duration": 0.015593,
     "end_time": "2024-01-20T11:46:59.655453",
     "exception": false,
     "start_time": "2024-01-20T11:46:59.639860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(text: str, tokenizer):\n",
    "    \"\"\"\n",
    "    Split a string into its tokens using the provided tokenizer.\n",
    "\n",
    "    Args:\n",
    "        text:         string\n",
    "        tokenizer:    tokenizer for the language\n",
    "\n",
    "    Returns:\n",
    "        tokenized list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text.lower() for tok in tokenizer.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "024ecd77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:46:59.671379Z",
     "iopub.status.busy": "2024-01-20T11:46:59.670960Z",
     "iopub.status.idle": "2024-01-20T11:46:59.676721Z",
     "shell.execute_reply": "2024-01-20T11:46:59.675312Z"
    },
    "papermill": {
     "duration": 0.016568,
     "end_time": "2024-01-20T11:46:59.679055",
     "exception": false,
     "start_time": "2024-01-20T11:46:59.662487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter, tokenizer, index: int):\n",
    "    \"\"\"\n",
    "    Return the tokens for the appropriate language.\n",
    "\n",
    "    Args:\n",
    "        data_iter:    text here\n",
    "        tokenizer:    tokenizer for the language\n",
    "        index:        index of the language in the tuple | (de=0, en=1)\n",
    "\n",
    "    Yields:\n",
    "        sequences based on index\n",
    "    \"\"\"\n",
    "    for from_tuple in data_iter:\n",
    "        yield tokenizer(from_tuple[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a02711d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:46:59.694844Z",
     "iopub.status.busy": "2024-01-20T11:46:59.694231Z",
     "iopub.status.idle": "2024-01-20T11:46:59.701456Z",
     "shell.execute_reply": "2024-01-20T11:46:59.700446Z"
    },
    "papermill": {
     "duration": 0.017458,
     "end_time": "2024-01-20T11:46:59.703577",
     "exception": false,
     "start_time": "2024-01-20T11:46:59.686119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_vocabulary(\n",
    "    spacy_de, spacy_en, train_iter, val_iter, test_iter, min_freq: int = 2\n",
    "):\n",
    "    def tokenize_de(text: str):\n",
    "        \"\"\"\n",
    "        Call the German tokenizer.\n",
    "\n",
    "        Args:\n",
    "            text:         string\n",
    "            min_freq:     minimum frequency needed to include a word in the vocabulary\n",
    "\n",
    "        Returns:\n",
    "            tokenized list of strings\n",
    "        \"\"\"\n",
    "        return tokenize(text, spacy_de)\n",
    "\n",
    "    def tokenize_en(text: str):\n",
    "        \"\"\"\n",
    "        Call the English tokenizer.\n",
    "\n",
    "        Args:\n",
    "            text:         string\n",
    "\n",
    "        Returns:\n",
    "            tokenized list of strings\n",
    "        \"\"\"\n",
    "        return tokenize(text, spacy_en)\n",
    "\n",
    "    print(\"Building German Vocabulary...\")\n",
    "\n",
    "    #     # load train, val, and test data pipelines\n",
    "    #     train, val, test = datasets.IWSLT2016(language_pair=(\"de\", \"en\"))\n",
    "    train = train_iter\n",
    "    val = val_iter\n",
    "    test = test_iter\n",
    "\n",
    "    # generate source vocabulary\n",
    "    vocab_src = build_vocab_from_iterator(\n",
    "        yield_tokens(\n",
    "            train + val + test, tokenize_de, index=0\n",
    "        ),  # tokens for each German sentence (index 0)\n",
    "        min_freq=min_freq,\n",
    "        specials=[\"<bos>\", \"<eos>\", \"<pad>\", \"<unk>\"],\n",
    "    )\n",
    "\n",
    "    print(\"Building English Vocabulary...\")\n",
    "\n",
    "    # generate target vocabulary\n",
    "    vocab_trg = build_vocab_from_iterator(\n",
    "        yield_tokens(\n",
    "            train + val + test, tokenize_en, index=1\n",
    "        ),  # tokens for each English sentence (index 1)\n",
    "        min_freq=2,  #\n",
    "        specials=[\"<bos>\", \"<eos>\", \"<pad>\", \"<unk>\"],\n",
    "    )\n",
    "\n",
    "    # set default token for out-of-vocabulary words (OOV)\n",
    "    vocab_src.set_default_index(vocab_src[\"<unk>\"])\n",
    "    vocab_trg.set_default_index(vocab_trg[\"<unk>\"])\n",
    "\n",
    "    return vocab_src, vocab_trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23000b10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:46:59.719234Z",
     "iopub.status.busy": "2024-01-20T11:46:59.718691Z",
     "iopub.status.idle": "2024-01-20T11:46:59.724940Z",
     "shell.execute_reply": "2024-01-20T11:46:59.723615Z"
    },
    "papermill": {
     "duration": 0.016715,
     "end_time": "2024-01-20T11:46:59.727311",
     "exception": false,
     "start_time": "2024-01-20T11:46:59.710596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_vocab(spacy_de, spacy_en, train_iter, val_iter, test_iter, min_freq: int = 2):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        spacy_de:     German tokenizer\n",
    "        spacy_en:     English tokenizer\n",
    "        min_freq:     minimum frequency needed to include a word in the vocabulary\n",
    "\n",
    "    Returns:\n",
    "        vocab_src:    German vocabulary\n",
    "        vocab_trg:     English vocabulary\n",
    "    \"\"\"\n",
    "\n",
    "    if not os.path.exists(\"vocab.pt\"):\n",
    "        # build the German/English vocabulary if it does not exist\n",
    "        vocab_src, vocab_trg = build_vocabulary(\n",
    "            spacy_de, spacy_en, train_iter, val_iter, test_iter, min_freq\n",
    "        )\n",
    "        # save it to a file\n",
    "        torch.save((vocab_src, vocab_trg), \"vocab.pt\")\n",
    "    else:\n",
    "        # load the vocab if it exists\n",
    "        vocab_src, vocab_trg = torch.load(\"vocab.pt\")\n",
    "\n",
    "    print(\"Finished.\\nVocabulary sizes:\")\n",
    "    print(\"\\tSource:\", len(vocab_src))\n",
    "    print(\"\\tTarget:\", len(vocab_trg))\n",
    "    return vocab_src, vocab_trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "140326ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:46:59.742812Z",
     "iopub.status.busy": "2024-01-20T11:46:59.742434Z",
     "iopub.status.idle": "2024-01-20T11:47:15.543991Z",
     "shell.execute_reply": "2024-01-20T11:47:15.542954Z"
    },
    "papermill": {
     "duration": 15.811363,
     "end_time": "2024-01-20T11:47:15.545959",
     "exception": false,
     "start_time": "2024-01-20T11:46:59.734596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting de-core-news-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m82.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from de-core-news-sm==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (68.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.24.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2023.11.17)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.3)\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-3.7.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('de_core_news_sm')\n",
      "Loaded English and German tokenizers.\n"
     ]
    }
   ],
   "source": [
    "# global variables used later in the script\n",
    "spacy_de, spacy_en = load_tokenizers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c878ae87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:47:15.562863Z",
     "iopub.status.busy": "2024-01-20T11:47:15.561864Z",
     "iopub.status.idle": "2024-01-20T11:47:19.213941Z",
     "shell.execute_reply": "2024-01-20T11:47:19.212581Z"
    },
    "papermill": {
     "duration": 3.66232,
     "end_time": "2024-01-20T11:47:19.215705",
     "exception": false,
     "start_time": "2024-01-20T11:47:15.553385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building German Vocabulary...\n",
      "Building English Vocabulary...\n",
      "Finished.\n",
      "Vocabulary sizes:\n",
      "\tSource: 7983\n",
      "\tTarget: 5979\n"
     ]
    }
   ],
   "source": [
    "vocab_src, vocab_trg = load_vocab(spacy_de, spacy_en, train_iter, val_iter, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e663585",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:47:19.232637Z",
     "iopub.status.busy": "2024-01-20T11:47:19.232284Z",
     "iopub.status.idle": "2024-01-20T11:47:19.237812Z",
     "shell.execute_reply": "2024-01-20T11:47:19.236517Z"
    },
    "papermill": {
     "duration": 0.016341,
     "end_time": "2024-01-20T11:47:19.239796",
     "exception": false,
     "start_time": "2024-01-20T11:47:19.223455",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BOS_IDX = vocab_trg[\"<bos>\"]\n",
    "EOS_IDX = vocab_trg[\"<eos>\"]\n",
    "PAD_IDX = vocab_trg[\"<pad>\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6462f314",
   "metadata": {
    "papermill": {
     "duration": 0.007154,
     "end_time": "2024-01-20T11:47:19.255229",
     "exception": false,
     "start_time": "2024-01-20T11:47:19.248075",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Perform data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0802d0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:47:19.272058Z",
     "iopub.status.busy": "2024-01-20T11:47:19.271461Z",
     "iopub.status.idle": "2024-01-20T11:47:19.278505Z",
     "shell.execute_reply": "2024-01-20T11:47:19.277563Z"
    },
    "papermill": {
     "duration": 0.018153,
     "end_time": "2024-01-20T11:47:19.280764",
     "exception": false,
     "start_time": "2024-01-20T11:47:19.262611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_process(raw_data):\n",
    "    \"\"\"\n",
    "    Process raw sentences by tokenizing and converting to integers based on\n",
    "    the vocabulary.\n",
    "\n",
    "    Args:\n",
    "        raw_data:     German-English sentence pairs\n",
    "    Returns:\n",
    "        data:         tokenized data converted to index based on vocabulary\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    # loop through each sentence pair\n",
    "    for raw_de, raw_en in tqdm(raw_data):\n",
    "        de_tensor_ = []\n",
    "        # tokenize the sentence and convert each word to an integers\n",
    "        for token in spacy_de.tokenizer(raw_de):\n",
    "            de_tensor_.append(vocab_src[token.text.lower()])\n",
    "\n",
    "        en_tensor_ = []\n",
    "        # tokenize the sentence and convert each word to an integers\n",
    "        for token in spacy_en.tokenizer(raw_en):\n",
    "            en_tensor_.append(vocab_trg[token.text.lower()])\n",
    "\n",
    "        de_tensor_ = torch.tensor(de_tensor_, dtype=torch.long)\n",
    "        en_tensor_ = torch.tensor(en_tensor_, dtype=torch.long)\n",
    "        # append tensor representations\n",
    "        data.append((de_tensor_, en_tensor_))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e88f7a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:47:19.298229Z",
     "iopub.status.busy": "2024-01-20T11:47:19.297133Z",
     "iopub.status.idle": "2024-01-20T11:47:22.389429Z",
     "shell.execute_reply": "2024-01-20T11:47:22.388454Z"
    },
    "papermill": {
     "duration": 3.104618,
     "end_time": "2024-01-20T11:47:22.393069",
     "exception": false,
     "start_time": "2024-01-20T11:47:19.288451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27550/27550 [00:02<00:00, 9778.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: 27550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1450/1450 [00:00<00:00, 10145.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val data shape: 1450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 9048.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# processed data\n",
    "train_data = data_process(train_iter)\n",
    "print(f\"Train data shape: {len(train_data)}\")\n",
    "val_data = data_process(val_iter)\n",
    "print(f\"Val data shape: {len(val_data)}\")\n",
    "test_data = data_process(test_iter)\n",
    "print(f\"Test data shape: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "060a228c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:47:22.416944Z",
     "iopub.status.busy": "2024-01-20T11:47:22.416575Z",
     "iopub.status.idle": "2024-01-20T11:47:22.424219Z",
     "shell.execute_reply": "2024-01-20T11:47:22.423382Z"
    },
    "papermill": {
     "duration": 0.021007,
     "end_time": "2024-01-20T11:47:22.426292",
     "exception": false,
     "start_time": "2024-01-20T11:47:22.405285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[2][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e889f1",
   "metadata": {
    "papermill": {
     "duration": 0.009825,
     "end_time": "2024-01-20T11:47:22.446330",
     "exception": false,
     "start_time": "2024-01-20T11:47:22.436505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Create collate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "496a4c4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:47:22.468297Z",
     "iopub.status.busy": "2024-01-20T11:47:22.467884Z",
     "iopub.status.idle": "2024-01-20T11:47:22.475409Z",
     "shell.execute_reply": "2024-01-20T11:47:22.474456Z"
    },
    "papermill": {
     "duration": 0.020811,
     "end_time": "2024-01-20T11:47:22.477226",
     "exception": false,
     "start_time": "2024-01-20T11:47:22.456415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_batch(data_batch):\n",
    "    \"\"\"\n",
    "    Process indexed-sequences by adding <bos>, <eos>, and <pad> tokens.\n",
    "\n",
    "    Args:\n",
    "        data_batch:     German-English indexed-sentence pairs\n",
    "\n",
    "    Returns:\n",
    "        two batches:    one for German and one for English\n",
    "    \"\"\"\n",
    "    de_batch, en_batch = [], []\n",
    "\n",
    "    # for each sentence\n",
    "    for de_item, en_item in data_batch:\n",
    "        # add <bos> and <eos> indices before and after the sentence\n",
    "        de_temp = torch.cat(\n",
    "            [torch.tensor([BOS_IDX]), de_item, torch.tensor([EOS_IDX])], dim=0\n",
    "        ).to(device)\n",
    "        en_temp = torch.cat(\n",
    "            [torch.tensor([BOS_IDX]), en_item, torch.tensor([EOS_IDX])], dim=0\n",
    "        ).to(device)\n",
    "\n",
    "        # add padding\n",
    "        de_batch.append(\n",
    "            pad(\n",
    "                de_temp,\n",
    "                (\n",
    "                    0,  # dimension to pad\n",
    "                    MAX_PADDING - len(de_temp),  # amount of padding to add\n",
    "                ),\n",
    "                value=PAD_IDX,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # add padding\n",
    "        en_batch.append(\n",
    "            pad(\n",
    "                en_temp,\n",
    "                (\n",
    "                    0,  # dimension to pad\n",
    "                    MAX_PADDING - len(en_temp),  # amount of padding to add\n",
    "                ),\n",
    "                value=PAD_IDX,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return torch.stack(de_batch), torch.stack(en_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49620c5f",
   "metadata": {
    "papermill": {
     "duration": 0.009848,
     "end_time": "2024-01-20T11:47:22.497419",
     "exception": false,
     "start_time": "2024-01-20T11:47:22.487571",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Data loaders Created for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d2cf47c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-20T11:47:22.577985Z",
     "iopub.status.busy": "2024-01-20T11:47:22.577627Z",
     "iopub.status.idle": "2024-01-20T11:47:22.588953Z",
     "shell.execute_reply": "2024-01-20T11:47:22.587702Z"
    },
    "papermill": {
     "duration": 0.025197,
     "end_time": "2024-01-20T11:47:22.591504",
     "exception": false,
     "start_time": "2024-01-20T11:47:22.566307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_PADDING = 20\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "train_iter = DataLoader(\n",
    "    to_map_style_dataset(train_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=generate_batch,\n",
    ")\n",
    "\n",
    "valid_iter = DataLoader(\n",
    "    to_map_style_dataset(val_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=generate_batch,\n",
    ")\n",
    "\n",
    "test_iter = DataLoader(\n",
    "    to_map_style_dataset(test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    collate_fn=generate_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf3aabd",
   "metadata": {
    "papermill": {
     "duration": 0.009822,
     "end_time": "2024-01-20T11:47:22.611572",
     "exception": false,
     "start_time": "2024-01-20T11:47:22.601750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1800581,
     "sourceId": 2936819,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 46.477843,
   "end_time": "2024-01-20T11:47:23.946112",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-20T11:46:37.468269",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
